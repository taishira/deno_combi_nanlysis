{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kanzen.csvというファイルを最終的な元データとして扱う\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import collections\n",
    "\n",
    "df = pd.read_csv('deno.land_dependencies_import_https_all.csv',encoding = \"shift_jis\")\n",
    "imp_li = df['import'].values.tolist()\n",
    "orig_li = df['original'].values.tolist()\n",
    "\n",
    "#for i in range(len(orig_li)):\n",
    "#    orig_li[i] = ast.literal_eval(orig_li[i])\n",
    "#\n",
    "#comb_li[i] = ast.literal_eval(comb_li[i])\n",
    "    \n",
    "a = []\n",
    "for i in range(len(imp_li)):\n",
    "    a.append([])\n",
    "    a[i].append(orig_li[i])\n",
    "    a[i].append(imp_li[i])\n",
    "\n",
    "#k = pd.DataFrame(a,columns=['original','import'])\n",
    "#k.to_csv(\"kanzen.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orig = pd.read_csv('import_side2.csv')\n",
    "df_impo = pd.read_csv('export_side2.csv')\n",
    "\n",
    "orig_li = df_orig.values.tolist()\n",
    "impo_li = df_impo.values.tolist()\n",
    "\n",
    "a = []\n",
    "for i in range(len(orig_li)):\n",
    "    a.append([])\n",
    "    d_orig = dict([('module', orig_li[i][0]), ('org', str(orig_li[i][1])), ('package', orig_li[i][2]), ('version', str(orig_li[i][3]))])\n",
    "    d_impo = dict([('module', impo_li[i][0]), ('org', str(impo_li[i][1])), ('package', str(impo_li[i][2])), ('version', str(impo_li[i][3]))])\n",
    "    a[i].append(d_orig)\n",
    "    a[i].append(d_impo)\n",
    "    \n",
    "k = pd.DataFrame(a,columns=['original','import'])\n",
    "k.to_csv(\"kanzen_dict.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "\n",
    "'''\n",
    "kannzenn_dict.csvには、[import],[export]の関係をまとめた。\n",
    "その結果、23675の依存関係を採集することができた。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3635\n",
      "20040\n",
      "23675\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_dict = pd.read_csv('kanzen_dict.csv')\n",
    "imp_li = df_dict['import'].values.tolist()\n",
    "orig_li = df_dict['original'].values.tolist()\n",
    "all_li = df_dict.values.tolist()\n",
    "\n",
    "for i in range(len(orig_li)):\n",
    "    orig_li[i] = ast.literal_eval(orig_li[i])\n",
    "    imp_li[i] = ast.literal_eval(imp_li[i])\n",
    "\n",
    "a = []\n",
    "b = []    \n",
    "for i in range(len(orig_li)):\n",
    "    if orig_li[i]['package'] == 'polkadot':\n",
    "        a.append([orig_li[i],imp_li[i]])\n",
    "    else:\n",
    "        b.append([orig_li[i],imp_li[i]])\n",
    "        \n",
    "        \n",
    "\n",
    "print(len(a))\n",
    "print(len(b))\n",
    "print(len(orig_li))\n",
    "\n",
    "#k = pd.DataFrame(a,columns=['original','import'])\n",
    "#k.to_csv(\"polkadot_dict.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "l = pd.DataFrame(b,columns=['original','import'])\n",
    "l.to_csv(\"polkadot_nashi_dict.csv\", encoding=\"shift_jis\", index = False) \n",
    "'''\n",
    "kanzen_dict.csvをpolkadotありとなしのcsvファイルに分類した。\n",
    "あり→20040個、　なし→3635個になり、polkadotという一つのコミュニティが大きい割合を示していたことが明らかになった。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'module': 'deno.land/x/30_seconds_of_typescript/util.test.ts', 'org': 'nan', 'package': '30_seconds_of_typescript', 'version': 'v1.0.1'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_dict = pd.read_csv('polkadot_nashi_dict.csv')\n",
    "imp_li = df_dict['import'].values.tolist()\n",
    "orig_li = df_dict['original'].values.tolist()\n",
    "\n",
    "for i in range(len(orig_li)):\n",
    "    orig_li[i] = ast.literal_eval(orig_li[i])\n",
    "    imp_li[i] = ast.literal_eval(imp_li[i])\n",
    "\n",
    "    \n",
    "\n",
    "print(orig_li[0])\n",
    "modname_li = []\n",
    "\n",
    "for i in range(len(orig_li)):\n",
    "     if orig_li[i] not in modname_li:\n",
    "            modname_li.append(orig_li[i])\n",
    "\n",
    "        \n",
    "ex_li = []\n",
    "kekka_li = []\n",
    "kekka_li2 = []#2以上\n",
    "for i in range(len(modname_li)):            \n",
    "    ex_li.append([])\n",
    "    kekka_li.append([])\n",
    "    \n",
    "for i in range(len(modname_li)):\n",
    "    for j in range(len(orig_li)):\n",
    "        if modname_li[i] == orig_li[j]:\n",
    "            ex_li[i].append(imp_li[j])\n",
    "\n",
    "            \n",
    "\n",
    "for i in range(len(ex_li)):\n",
    "    kekka_li[i].append(modname_li[i])\n",
    "    kekka_li[i].append(ex_li[i])\n",
    "    \n",
    "for i in range(len(kekka_li)):\n",
    "    if len(ex_li[i]) > 1:\n",
    "        kekka_li2.append([modname_li[i],ex_li[i]])\n",
    "\n",
    "#k = pd.DataFrame(kekka_li,columns=['original','imports'])\n",
    "#k.to_csv(\"polkadot_nashi_allimports.csv\", encoding=\"shift_jis\", index = False) \n",
    "\n",
    "l = pd.DataFrame(kekka_li2,columns=['original','imports'])\n",
    "l.to_csv(\"polkadot_nashi_over2imports_kari.csv\", encoding=\"shift_jis\", index = False) \n",
    "'''\n",
    "polkadotなしのファイルから、originalの部分が一致するimport先を集めたファイルを作った。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_li = []#memo\n",
    "\n",
    "for i in range(len(orig_li)):\n",
    "    for j in range(len(orig_li)):\n",
    "\n",
    "        if orig_li[i]['module'] == orig_li[j]['module']:\n",
    "            if orig_li[j] not in ex_li:\n",
    "                ex_li.append(orig_li[j]['module'])\n",
    "    print(list(set(ex_li)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#「組み合わせ」,「importしているモジュール」のファイルをつくる\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_dict = pd.read_csv('polkadot_nashi_over2imports.csv')\n",
    "imp_li = df_dict['imports'].values.tolist()\n",
    "orig_li = df_dict['original'].values.tolist()\n",
    "\n",
    "for i in range(len(orig_li)):\n",
    "    orig_li[i] = ast.literal_eval(orig_li[i])\n",
    "    imp_li[i] = ast.literal_eval(imp_li[i])\n",
    "\n",
    "a = []    \n",
    "b = []    \n",
    "for i in range(len(orig_li)):\n",
    "    a.append([])\n",
    "    b.append([])\n",
    "for i in range(len(orig_li)):\n",
    "    for j in range(len(imp_li[i])):\n",
    "        a[i].append(imp_li[i][j]['module'])\n",
    "        \n",
    "for i in range(len(orig_li)):\n",
    "    b[i].append(orig_li[i])\n",
    "    b[i].append(imp_li[i])\n",
    "    b[i].append(a[i])\n",
    "    \n",
    "l = pd.DataFrame(b,columns=['original','import','ver_nashi'])\n",
    "l.to_csv(\"polkadot_nashi_o2vernashi.csv\", encoding=\"shift_jis\", index = False) \n",
    "\n",
    "\n",
    "'''\n",
    "組み合わせの集計のために、versionなしのimportリストを作った。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deno.land/std/fs/mod.ts', 'deno.land/std/path/mod.ts', 'deno.land/std/fs/mod.ts', 'deno.land/std/path/mod.ts']\n",
      "295902\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df = pd.read_csv('polkadot_nashi_o2vernashi.csv',encoding = \"latin-1\")\n",
    "all_mod_list = df['ver_nashi'].values.tolist()\n",
    "#all_list = df.values.tolist()\n",
    "\n",
    "#all_mod = []\n",
    "\n",
    "\n",
    "for i in range(len(all_mod_list)):\n",
    "    all_mod_list[i]=ast.literal_eval(all_mod_list[i])\n",
    "\n",
    "n = len(all_mod_list)\n",
    "\n",
    "print(all_mod_list[0])\n",
    "    \n",
    "\n",
    "new_list = []\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if j != i:\n",
    "            #kumi_list = []\n",
    "            #kumi_list2 = []\n",
    "            x = {}\n",
    "            x = set(all_mod_list[i]) & set(all_mod_list[j])\n",
    "            \n",
    "            if len(x) > 1:\n",
    "                #kumi_list.append(x)\n",
    "                #kumi_list2.append(all_list[j][0])\n",
    "                #kumi_list2.append(all_list[i][0])\n",
    "                #kumi_list.append(kumi_list2)\n",
    "                new_list.append([x])\n",
    "                \n",
    "print(len(new_list))  \n",
    "\n",
    "exist_li = []\n",
    "new_list_a = []\n",
    "for i in range(len(new_list)):\n",
    "    if new_list[i] not in exist_li:\n",
    "        new_list_a.append(list(new_list[i]))\n",
    "        exist_li.append(new_list[i])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "k = pd.DataFrame(new_list_a,\n",
    "                  columns=['combination'])\n",
    "k.to_csv(\"combination_kari.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "\n",
    "'''\n",
    "存在する組み合わせのリストを作った。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_combi = pd.read_csv('combination.csv')\n",
    "df = pd.read_csv('polkadot_nashi_o2vernashi.csv',encoding = \"latin-1\")\n",
    "all_mod_li = df['ver_nashi'].values.tolist()\n",
    "orig_li = df['original'].values.tolist()\n",
    "imp_li = df['import'].values.tolist()\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "\n",
    "for i in range(len(all_mod_li)):\n",
    "    all_mod_li[i]=ast.literal_eval(all_mod_li[i])\n",
    "    orig_li[i]=ast.literal_eval(orig_li[i])\n",
    "    \n",
    "x = set(all_mod_li[0]) & combi_li[0]\n",
    "\n",
    "print(combi_li[0] <= set(all_mod_li[0]))\n",
    "a = []\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    a.append([])\n",
    "\n",
    "for i in range(len(all_mod_li)):\n",
    "    for j in range(len(combi_li)):\n",
    "        if combi_li[j] <= set(all_mod_li[i]):\n",
    "            a[j].append(orig_li[i])\n",
    "            \n",
    "            \n",
    "new_li = []\n",
    "for i in range(len(combi_li)):\n",
    "    new_li.append([])\n",
    "    new_li[i].append(combi_li[i])\n",
    "    new_li[i].append(a[i])\n",
    "    \n",
    "\n",
    "k = pd.DataFrame(new_li,\n",
    "                  columns=['combination','originals'])\n",
    "k.to_csv(\"conbi_orig.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_combi = pd.read_csv('combi_orig.csv')\n",
    "df_dict = pd.read_csv('polkadot_nashi_o2vernashi.csv',encoding = \"latin-1\")\n",
    "all_mod_li = df_dict['ver_nashi'].values.tolist()\n",
    "orig_li = df_dict['original'].values.tolist()\n",
    "imp_li = df_dict['import'].values.tolist()\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "combi_orig = df_combi['originals'].values.tolist()\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "    combi_orig[i]=ast.literal_eval(combi_orig[i])\n",
    "    \n",
    "for i in range(len(all_mod_li)):\n",
    "    all_mod_li[i]=ast.literal_eval(all_mod_li[i])\n",
    "    orig_li[i]=ast.literal_eval(orig_li[i])\n",
    "    imp_li[i]=ast.literal_eval(imp_li[i])\n",
    "    \n",
    "a = []\n",
    "a_2 = []\n",
    "for i in range(len(combi_orig)):\n",
    "    a.append([])\n",
    "    a_2.append([])\n",
    "\n",
    "for i in range(len(combi_orig)):\n",
    "    for j in range(len(combi_orig[i])):\n",
    "        \n",
    "        for k in range(len(orig_li)):\n",
    "            \n",
    "            if combi_orig[i][j]['module'] == orig_li[k]['module']:\n",
    "                li = []\n",
    "                for l in list(combi_li[i]):\n",
    "                    for m in imp_li[k]:\n",
    "                        if l == m['module']:\n",
    "                            li.append(m)\n",
    "                a_2[i].append(li)\n",
    "                if len(li) == len(combi_li[i]):\n",
    "                    a[i].append(li)    #セット型で比べろ！！\n",
    "\n",
    "#combi_origのリストにaを追加したい\n",
    "\n",
    "b = []\n",
    "b_2 = []\n",
    "for i in range(len(combi_li)):\n",
    "    b.append([])\n",
    "    b[i].append(combi_li[i])\n",
    "    b[i].append(combi_orig[i])\n",
    "    b[i].append(a[i])\n",
    "    b_2.append([])\n",
    "    b_2[i].append(combi_li[i])\n",
    "    b_2[i].append(combi_orig[i])\n",
    "    b_2[i].append(a_2[i])\n",
    "\n",
    "    \n",
    "#k = pd.DataFrame(b,\n",
    "#                  columns=['combination','originals','rekkyo'])\n",
    "#k.to_csv(\"kumiawase_rekkyo_kari.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "k = pd.DataFrame(b_2,\n",
    "                  columns=['combination','originals','rekkyo'])\n",
    "k.to_csv(\"kumiawase_rekkyo_all.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('kumiawase_rekkyo_all.csv')\n",
    "\n",
    "\n",
    "\n",
    "k = df[df['combination'].str.contains('polkadot')]\n",
    "k.to_csv(\"kumiawase_rekkyo_polkadotari_all.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv('kumiawase_rekkyo_all.csv')#元はkariだった\n",
    "\n",
    "df[~(df['combination'].str.contains('polkadot'))]\n",
    "\n",
    "k = df[~(df['combination'].str.contains('polkadot'))]\n",
    "k.to_csv(\"kumiawase_rekkyo_polkadotnashi_all.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deno.land/std/fs/mod.ts', 'deno.land/std/path/mod.ts']\n",
      "736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nversion列挙のために、importした数が数を組み合わせの数に合致するものを評価したが、\\n母数に入れたいので、それではないcsvファイルも一応作っておきたい。\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_combi = pd.read_csv('kumiawase_rekkyo_polkadotnashi_all.csv')\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "combi_orig = df_combi['originals'].values.tolist()\n",
    "combi_rekkyo = df_combi['rekkyo'].values.tolist()\n",
    "\n",
    "li = []\n",
    "li_2 = []#tasita\n",
    "combi_rekkyo_2 = []\n",
    "combi_orig_2 = []\n",
    "for i in range(len(combi_li)):\n",
    "    combi_rekkyo_2.append([])#tasita\n",
    "    combi_rekkyo_2[i]=ast.literal_eval(combi_rekkyo[i])#tasita\n",
    "    combi_orig_2.append([])#tasita\n",
    "    combi_orig_2[i]=ast.literal_eval(combi_orig[i])#tasita\n",
    "    \n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "    combi_orig[i]=ast.literal_eval(combi_orig[i])\n",
    "    combi_rekkyo[i]=ast.literal_eval(combi_rekkyo[i])\n",
    "    combi_li[i] = list(combi_li[i])\n",
    "    li.append([])\n",
    "    li_2.append([])\n",
    "    #print(len(combi_orig[i]),len(combi_rekkyo[i]))\n",
    "    \n",
    "print(combi_li[0])\n",
    "print(len(combi_rekkyo[0])) \n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    for j in range(len(combi_li)):\n",
    "        if i != j:\n",
    "            if set(combi_li[i]) <= set(combi_li[j]):\n",
    "                #combi_orig_2[i].extend(combi_orig_2[j])\n",
    "                \n",
    "                for l in range(len(combi_rekkyo[j])):\n",
    "                    a = []\n",
    "                    b = []\n",
    "                    for m in range(len(combi_rekkyo[j][l])):\n",
    "                        if combi_rekkyo[j][l][m]['module'] in combi_li[i]:\n",
    "                            a.append(combi_rekkyo[j][l][m])\n",
    "                            b.append(combi_rekkyo[j][l][m]['module'])\n",
    "                            \n",
    "                    li_2.append(a)#tasita\n",
    "                    if len(a) == len(combi_li[i]):\n",
    "                        if len(list(set(b))) == len(combi_li[i]):\n",
    "                            li[i].append(a)\n",
    "    combi_rekkyo[i].extend(li[i])\n",
    "    \n",
    "    \n",
    "\n",
    "#print(combi_rekkyo[0])\n",
    "kansei_li = []\n",
    "kansei_li_2 = []#tasita\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    kansei_li.append([])\n",
    "    kansei_li[i].append(combi_li[i])\n",
    "    kansei_li[i].append(combi_orig[i])\n",
    "    kansei_li[i].append(combi_rekkyo[i])\n",
    "    \n",
    "    kansei_li_2.append([])#tasita\n",
    "    kansei_li_2[i].append(combi_li[i])\n",
    "    kansei_li_2[i].append(combi_orig_2[i])\n",
    "    kansei_li_2[i].append(combi_rekkyo_2[i])\n",
    "    \n",
    "\n",
    "                    \n",
    "                            \n",
    "#k = pd.DataFrame(kansei_li,\n",
    "#                  columns=['combination','originals','rekkyo'])\n",
    "#k.to_csv(\"kumiawase_rekkyo_kansei.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "k2 = pd.DataFrame(kansei_li_2,\n",
    "                  columns=['combination','originals','rekkyo'])\n",
    "k2.to_csv(\"kumiawase_rekkyo_all_kansei.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "\n",
    "'''\n",
    "version列挙のために、importした数が数を組み合わせの数に合致するものを評価したが、\n",
    "母数に入れたいので、それではないcsvファイルも一応作っておきたい。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deno.land/std/fs/mod.ts', 'deno.land/std/path/mod.ts']\n",
      "253\n",
      "1274\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_combi = pd.read_csv('kumiawase_rekkyo_kansei.csv')\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "combi_orig = df_combi['originals'].values.tolist()\n",
    "combi_rekkyo = df_combi['rekkyo'].values.tolist()\n",
    "\n",
    "li = []\n",
    "for i in range(len(combi_li)):\n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "    combi_orig[i]=ast.literal_eval(combi_orig[i])\n",
    "    combi_rekkyo[i]=ast.literal_eval(combi_rekkyo[i])\n",
    "    combi_li[i] = list(combi_li[i])\n",
    "    li.append([])\n",
    "    \n",
    "print(combi_li[0])\n",
    "print(len(combi_orig[0])) \n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    for j in range(len(combi_li)):\n",
    "        if i != j:\n",
    "            if set(combi_li[i]) <= set(combi_li[j]):\n",
    "                combi_orig[i].extend(combi_orig[j])\n",
    "                \n",
    "\n",
    "print(len(combi_orig[0]))\n",
    "\n",
    "kansei_li = []\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    kansei_li.append([])\n",
    "    kansei_li[i].append(combi_li[i])\n",
    "    kansei_li[i].append(combi_orig[i])\n",
    "    kansei_li[i].append(combi_rekkyo[i])\n",
    "\n",
    "    \n",
    "    \n",
    "k = pd.DataFrame(kansei_li,\n",
    "                  columns=['combination','originals','rekkyo'])\n",
    "k.to_csv(\"kumiawase_rekkyo_kanzenban.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df_combi = pd.read_csv('kumiawase_rekkyo_kanzenban.csv')\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "combi_orig = df_combi['originals'].values.tolist()\n",
    "combi_rekkyo = df_combi['rekkyo'].values.tolist()\n",
    "\n",
    "li = []\n",
    "b = [] \n",
    "for i in range(len(combi_li)):\n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "    combi_orig[i]=ast.literal_eval(combi_orig[i])\n",
    "    combi_rekkyo[i]=ast.literal_eval(combi_rekkyo[i])\n",
    "    combi_li[i] = list(combi_li[i])\n",
    "    li.append([])\n",
    "    b.append([])\n",
    "    \n",
    "    \n",
    "    \n",
    "for i in range(len(combi_rekkyo)):\n",
    "    for j in range(len(combi_rekkyo[i])):\n",
    "        a = []\n",
    "        for k in combi_rekkyo[i][j]:\n",
    "            a.append(k['version'])\n",
    "        #print(a)\n",
    "        li[i].append(a)\n",
    "    #print(len(li[i]))\n",
    "\n",
    "\n",
    "for i in range(len(combi_li)):\n",
    "    b[i].append(combi_li[i])\n",
    "    b[i].append(li[i])\n",
    "    \n",
    "k = pd.DataFrame(b,\n",
    "                  columns=['combination','version_rekkyo'])\n",
    "k.to_csv(\"combi_versionrekkyo.csv\", encoding=\"shift_jis\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.125.0', '0.125.0'], ['0.0.0', '0.0.0'], ['0.125.0', '0.125.0'], ['0.85.0', '0.85.0'], ['0.85.0', '0.85.0']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(0,len(version_li[0])-1,1):\\n    for j in range(i,len(version_li[0]),1):\\n        if version.parse(version_li[0][j][0]) < version.parse(version_li[0][i][0]):\\n            minimal_li = version_li[0][i]\\n            version_li[0][j] = version_li[0][i]\\n            version_li[0][i] = version_li[0][j]\\n\\n            \\nprint(version_li[0])\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from packaging import version\n",
    "\n",
    "df_combi = pd.read_csv('combi_versionrekkyo.csv')\n",
    "combi_li = df_combi['combination'].values.tolist()\n",
    "version_li = df_combi['version_rekkyo'].values.tolist()\n",
    "\n",
    "li = []\n",
    "b = [] \n",
    "for i in range(len(combi_li)):\n",
    "    combi_li[i]=ast.literal_eval(combi_li[i])\n",
    "    version_li[i]=ast.literal_eval(version_li[i])\n",
    "    li.append([])\n",
    "    b.append([])\n",
    "\n",
    "    \n",
    "#print(version_li[0])\n",
    "\n",
    "for i in range(len(version_li)):\n",
    "    for j in range(len(version_li[i])):\n",
    "        for k in range(len(version_li[i][j])):\n",
    "            if version_li[i][j][k] == 'nan':\n",
    "                version_li[i][j][k] = '0.0.0' #バージョン定義されていないものを'0.0.0'と据え変えて置く。\n",
    "                \n",
    "#print(version_li[0])\n",
    "    \n",
    "\n",
    "#まず、左側の値をparse_versionにかけて小さい順に並び替えて、matpotlibで\n",
    "\n",
    "minamal_ver = ''\n",
    "minimal_id = 0\n",
    "minimal_li = []\n",
    "hidari_li = []\n",
    "kansei_li = []\n",
    "a = []\n",
    "for i in range(len(version_li[613])):\n",
    "    hidari_li.append(version_li[613][i][0])\n",
    "\n",
    "    \n",
    "for i in range(0,len(hidari_li)-1,1):\n",
    "    for j in range(i,len(hidari_li),1):\n",
    "        if version.parse(hidari_li[j]) < version.parse(hidari_li[i]):\n",
    "            minimal_ver = hidari_li[i]\n",
    "            hidari_li[i] = hidari_li[j]\n",
    "            hidari_li[j] = minimal_ver\n",
    "    \n",
    "\n",
    "\n",
    "for i in range(len(hidari_li)):\n",
    "    for j in range(len(version_li[613])):\n",
    "        if j not in minimal_li:\n",
    "            if hidari_li[i] == version_li[613][j][0]:\n",
    "                kansei_li.append(version_li[0][j])\n",
    "                minimal_li.append(j)\n",
    "                \n",
    "print(kansei_li)\n",
    "\n",
    "k = pd.DataFrame(kansei_li)\n",
    "k.to_csv(\"graph_ka.csv\", encoding=\"shift_jis\", index = False)\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(len(version_li)):\n",
    "    for j in range(len(version_li[i])):\n",
    "        if j not in minimal_id_li:\n",
    "            minimal_li = version_li[i][j]\n",
    "            if version.parse(version_li[i][j][0]) < version.parse(minimal_li[0]):\n",
    "                minimal_li = version_li[i][j]\n",
    "                minimal_id = j\n",
    "            \n",
    "    li[i].append(minimal_li)\n",
    "    minimal_id_li.append(minimal_id)\n",
    "'''\n",
    "'''\n",
    "for i in range(0,len(version_li[0])-1,1):\n",
    "    for j in range(i,len(version_li[0]),1):\n",
    "        if version.parse(version_li[0][j][0]) < version.parse(version_li[0][i][0]):\n",
    "            minimal_li = version_li[0][i]\n",
    "            version_li[0][j] = version_li[0][i]\n",
    "            version_li[0][i] = version_li[0][j]\n",
    "\n",
    "            \n",
    "print(version_li[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0, 2, 1, 1]\n",
      "[20, 10, 20, 20, 20]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x160b88574e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from packaging import version\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_combi = pd.read_csv('graph_ka.csv')\n",
    "\n",
    "version_li = df_combi.values.tolist()\n",
    "\n",
    "li = []\n",
    "b = [] \n",
    "x = []\n",
    "y = []\n",
    "color = []\n",
    "minimal_ver = ''\n",
    "str_version_li = []\n",
    "count_li = []\n",
    "str_li = []\n",
    "moji_li = []\n",
    "y_count = []\n",
    "for i in version_li:\n",
    "    x.append(i[0])\n",
    "    y.append(i[1])\n",
    "\n",
    "b = list(set(y))\n",
    "\n",
    "#print(b)\n",
    "    \n",
    "for i in range(len(version_li)):\n",
    "    if version.parse(version_li[i][0]) == version.parse(version_li[i][1]):\n",
    "        color.append('b')\n",
    "        \n",
    "    if version.parse(version_li[i][0]) < version.parse(version_li[i][1]):\n",
    "        color.append('r')\n",
    "        \n",
    "    if version.parse(version_li[i][0]) > version.parse(version_li[i][1]):\n",
    "        color.append('y')\n",
    "\n",
    "for i in range(0,len(b)-1,1):\n",
    "    for j in range(i,len(b),1):\n",
    "        if version.parse(b[j]) < version.parse(b[i]):\n",
    "            minimal_ver = b[i]\n",
    "            b[i] = b[j]\n",
    "            b[j] = minimal_ver\n",
    "            \n",
    "            \n",
    "for i in range(len(version_li)):\n",
    "    str_li.append(str(version_li[i]))\n",
    "    \n",
    "for i in range(len(y)):\n",
    "    for j in range(len(b)):\n",
    "        if y[i] == b[j]:\n",
    "            y_count.append(j)\n",
    "            \n",
    "print(y_count)\n",
    "\n",
    "for i in range(len(str_li)):\n",
    "    count_li.append(str_li.count(str_li[i]))\n",
    "    count_li[i]*=10\n",
    "        \n",
    "\n",
    "\n",
    "print(count_li)\n",
    "for i in range(len(b)):\n",
    "    li.append(i)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.xticks(rotation=90)#文字を90度回転（文字の重なりを消去）\n",
    "plt.yticks(li,b)\n",
    "plt.xlabel('path',fontsize = 30)\n",
    "plt.ylabel('fs',fontsize = 30)\n",
    "plt.grid(True)\n",
    "plt.scatter(x, y_count, c = color, s = count_li, alpha=1)\n",
    "\n",
    "#同じだったら青色、x軸の方が低かったら赤色、y軸の方が低かったら緑色"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
